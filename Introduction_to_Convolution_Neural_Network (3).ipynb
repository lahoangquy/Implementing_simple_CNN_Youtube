{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Convolution Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Artificial Neural network (ANN)\n",
        "\n",
        "The structure of the neural networks contains the input layer, hidden layers and output layer. So normally the information will be received by the input signal and then it will transferred to the hidden layers where all information will be processed. Finally, after processing all information, output will be released by output layer. This is how simple artificial neural networks work.\n",
        "\n",
        "Convolution Neural networks are ANNs (artificial neural networks). CNNs (convolutional neural networks) are made of up neurons that are connected to one another by weighted branches (weight); the training parameters of the networks are once again the weight and bias. In CNNs, the connection pattern between neurons is inspired by the structure of the visual cortex in the animal world. The individual neurons that are present in this part of the brain (visual cortex) respond to certain stimuli in a narrow region of the observation, called the receptive field. The receptive fields of different neurons are partially overlapped to cover the entire field of vision. The response of a signle neuron to stimuli taking pace in its receptive field can be mathematically approximated by a convolution operation.\n",
        "\n",
        "CNNs contains input layers, convolution layers, pooling layers fully connected layers and output layers.\n",
        "\n",
        "\n",
        "Convolution layer.\n",
        "\n",
        "This is the main type of layer; the use of one or more of these layers in CNNs are essentials. Convolution layers have neurons which are organized in 3 dimensions, such as width, height and depth.\n",
        "\n",
        "During the forward propagation, each filer which is spatially small (along the width and height dimensions) and extends over the entire depth of the input volumne to which it is applied, is translated or convoluted with the width and height of the input volumn producing a 2 dimensional activation map (or feature map) for that filer. As the filer moved alon ghte input area, a scalar product operation is performed between the values of the filer and those of the input portion to which it is applied.\n",
        "\n",
        "The goal of the network is to learn activated filters in the presence of some specific type of functionality in a given spatial region of the input. The queuing of all these feature maps (for all filers), and the depth dimension form the putput volumn of a convolution layer. Each element of this volumn can be interpreted as the output of a neuron that observes only a small region of the input which shares its parameters with the other neurons that in the same feature map. This is because these values all come from the application of the same filter."
      ],
      "metadata": {
        "id": "ouKlK3wB_wxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pooling layers**\n",
        "\n",
        "\n",
        "These layers are inserted into a network to reduce the spatial size (width and height) of current representations, as well as volumnes in a specific network stage; This serves to reduce the number of parameters and the computational time of the network. It also monitors overfitting. A pooling layer operates on each depth slice of the input volumn independently to resize it spatially.\n",
        "\n",
        "For each feature obtained in the convolutional step, a matrix will be bilt and we will find the maximum in each chosen matrix to shrink the entire input. The steps will be:\n",
        "\n",
        "\n",
        "1.   Pick a window size (2 or 3)\n",
        "\n",
        "1.   Pick a stride moving range of pixels (usually 2)\n",
        "2.   Slide the window across the filtered images\n",
        "\n",
        "\n",
        "2.   For each window, the maximum value will be chosen.\n",
        "\n",
        "\n",
        "A pooling lyers will divide input into regions and selects a single representative value (max pooling and average pooling).\n",
        "\n",
        "The max pool layer will select the maximum numnber of features that have been detected by the convolution layers that precede it. The output will check whether a hypothetical feature is present in a region of the previous layers or not, but not exactly where. Hence, the idea is to allow the successive layers to worn on larger selection of data. Max pooling allows for faster convergence rates, and therefore, allow us to select higher invariant features to improve the generalization performance.\n",
        "\n",
        "\n",
        "There are 2 main advantages of using pooling layer. The first advantage will be to reduce the calculation of subsequent layers adn the second advantage will be increase the robustness of the features with respect to spatial position.\n",
        "\n"
      ],
      "metadata": {
        "id": "vDCJ13oOSkjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the MNIST digits data set and we can access to this dataset via keras library"
      ],
      "metadata": {
        "id": "57r1jlllMqsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement basic CNN\n",
        "# First step is we need to import and load all neccessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "d8-C2O78Mdqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The second step is we need to load the data and reshape the images in a 4-dimensional matrix\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# Reshape\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28,28,1)\n",
        "# Padding the images by 2 pixels\n",
        "x_train=np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "x_test=np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WroO9eEYM8OU",
        "outputId": "f5f33178-6121-455a-b324-be1b174231cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST dataset includes training and test datasets. These datasets are composed of the grayscale images (integer arrays with shape (num_sample, 28,28)) and the labels (integers in the range 0-9). Images are padded by 2 pixels because the input images were 32x32.\n",
        "\n",
        "\n",
        "The next step is model parameters need to be set and the deph of the image (number of channels) will be 1. The reason for that is these images are grayscale."
      ],
      "metadata": {
        "id": "UsTm2OirNuWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_width= x_train[0].shape[0]\n",
        "image_height= x_train[0].shape[1]\n",
        "num_channels = 1 # grayscale = 1 channel\n",
        "seed= 98\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "-2u3sSoXOVH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next is training and test data variables will be declared and there will be various batch sizes for traing and evaluation. These values can be changed depending on the physical memory that is avaible for training and evaluating."
      ],
      "metadata": {
        "id": "eFjvdhCNOp9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "evaluation_size = 500\n",
        "epochs=300\n",
        "eval_every=5"
      ],
      "metadata": {
        "id": "IELxLQWsO-a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " our images need to be normalized to change the values of all pixels to a common scale\n",
        "\n"
      ],
      "metadata": {
        "id": "zuLCYHhpPHSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "x_test= x_test/255"
      ],
      "metadata": {
        "id": "YyWgFfYBPHEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will declare our model. We will have the feature extractor module composed of 2 convolutional/ReLu/max pooling layers followed by the classifier with fully connected layers. Also, to get the classifier to work, we flatten the output of the feature extractor module so we can use it in the classifier.We will use a softmaxt activation function at the last layer of the classifier. Softmax will turn numeric output (logits) into probabilities that sum to one."
      ],
      "metadata": {
        "id": "R09uNbeGeTPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.keras.Input(dtype=tf.float32, shape=(image_width,image_height, num_channels), name=\"INPUT\")\n",
        "# First Conv-ReLU-MaxPool Layer\n",
        "conv1 = tf.keras.layers.Conv2D(filters=6,\n",
        "                               kernel_size=5,\n",
        "                               padding='VALID',\n",
        "                               activation=\"relu\",\n",
        "                               name=\"C1\")(input_data)\n",
        "max_pool1 = tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                      strides=2, \n",
        "                                      padding='SAME',\n",
        "                                      name=\"S1\")(conv1)\n",
        "# Second Conv-ReLU-MaxPool Layer\n",
        "conv2 = tf.keras.layers.Conv2D(filters=16,\n",
        "                               kernel_size=5,\n",
        "                               padding='VALID',\n",
        "                               strides=1,\n",
        "                               activation=\"relu\",\n",
        "                               name=\"C3\")(max_pool1)\n",
        "max_pool2 = tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                      strides=2, \n",
        "                                      padding='SAME',\n",
        "                                      name=\"S4\")(conv2)\n",
        "# Flatten Layer\n",
        "flatten = tf.keras.layers.Flatten(name=\"FLATTEN\")(max_pool2)\n",
        "# First Fully Connected Layer\n",
        "fully_connected1 = tf.keras.layers.Dense(units=120,\n",
        "                                         activation=\"relu\",\n",
        "                                         name=\"F5\")(flatten)\n",
        "# Second Fully Connected Layer\n",
        "fully_connected2 = tf.keras.layers.Dense(units=84,\n",
        "                                         activation=\"relu\",\n",
        "                                         name=\"F6\")(fully_connected1)\n",
        "# Final Fully Connected Layer\n",
        "final_model_output = tf.keras.layers.Dense(units=10,\n",
        "                                           activation=\"softmax\",\n",
        "                                           name=\"OUTPUT\"\n",
        "                                           )(fully_connected2)\n",
        "    \n",
        "model = tf.keras.Model(inputs= input_data, outputs=final_model_output)\n"
      ],
      "metadata": {
        "id": "FwYkQepUew01"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}